{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from openai import OpenAI\n",
    "\n",
    "# Configure OpenAI client for DeepInfra\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    "    api_key=\"0jxRzr6VTMJsMSnR2NomXgP0PKDkEEw5\",\n",
    ")\n",
    "\n",
    "# Initialize Qdrant client\n",
    "qdrant_client = QdrantClient(\":memory:\")  # Use in-memory for testing, or specify host\n",
    "\n",
    "# Create collection with BGE model dimensions (768)\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=\"my_collection\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=768,  # BAAI/bge-base-en-v1.5 outputs 768-dimensional vectors\n",
    "        distance=models.Distance.COSINE,  # BGE models use cosine similarity\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate embeddings using DeepInfra\n",
    "texts = [\"The food was delicious and the waiter...\", \"Another example text\"]\n",
    "vectors = []\n",
    "\n",
    "for text in texts:\n",
    "    response = client.embeddings.create(\n",
    "        model=\"BAAI/bge-base-en-v1.5\",\n",
    "        input=text,\n",
    "        encoding_format=\"float\"  # Optional but explicit\n",
    "    )\n",
    "    vectors.append(response.data[0].embedding)\n",
    "\n",
    "# Upload to Qdrant\n",
    "qdrant_client.upload_points(\n",
    "    collection_name=\"my_collection\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx,\n",
    "            vector=vector,\n",
    "            payload={\"text\": text}\n",
    "        )\n",
    "        for idx, (vector, text) in enumerate(zip(vectors, texts))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate query embedding\n",
    "query = \"restaurant experience\"\n",
    "response = client.embeddings.create(\n",
    "    model=\"BAAI/bge-base-en-v1.5\",\n",
    "    input=query,\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "query_vector = response.data[0].embedding\n",
    "\n",
    "# Search in Qdrant\n",
    "hits = qdrant_client.query_points(\n",
    "    collection_name=\"my_collection\",\n",
    "    query=query_vector,\n",
    "    limit=3\n",
    ").points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The food was delicious and the waiter...'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits[0].payload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
